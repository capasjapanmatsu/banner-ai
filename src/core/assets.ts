import fs from "fs-extra";
import path from "node:path";
import crypto from "node:crypto";
import fg from "fast-glob";
import sizeOf from "image-size";

export type AssetInfo = {
  path: string;
  hash: string;
  size: { width: number; height: number };
  fileSize: number;
  ext: string;
  basename: string;
};

export type DuplicateGroup = {
  hash: string;
  count: number;
  totalSize: number;
  files: AssetInfo[];
  recommended: AssetInfo; // æ®‹ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«
};

// ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
async function calculateHash(filePath: string): Promise<string> {
  const buffer = await fs.readFile(filePath);
  return crypto.createHash("md5").update(buffer).digest("hex");
}

// ç”»åƒæƒ…å ±å–å¾—
async function getImageInfo(filePath: string): Promise<AssetInfo | null> {
  try {
    const stats = await fs.stat(filePath);
    const buffer = await fs.readFile(filePath);
    const dimensions = sizeOf(buffer);
    const hash = await calculateHash(filePath);

    if (!dimensions.width || !dimensions.height) {
      return null;
    }

    return {
      path: filePath,
      hash,
      size: { width: dimensions.width, height: dimensions.height },
      fileSize: stats.size,
      ext: path.extname(filePath).toLowerCase(),
      basename: path.basename(filePath, path.extname(filePath)),
    };
  } catch (error) {
    console.warn(`âš ï¸ Failed to analyze: ${filePath}`, error);
    return null;
  }
}

// ã‚¢ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
export async function scanAssets(
  assetDirs: string[] = ["./src/assets", "./public"]
): Promise<AssetInfo[]> {
  const imageExts = [
    ".jpg",
    ".jpeg",
    ".png",
    ".gif",
    ".webp",
    ".bmp",
    ".tiff",
    ".svg",
  ];
  const assets: AssetInfo[] = [];

  console.log("ğŸ” Scanning asset directories...");

  for (const dir of assetDirs) {
    if (!(await fs.pathExists(dir))) {
      console.log(`ğŸ“ Directory not found: ${dir}`);
      continue;
    }

    const patterns = imageExts.map((ext) => path.join(dir, `**/*${ext}`));
    const files = await fg(patterns, { onlyFiles: true });

    console.log(`ğŸ“‚ ${dir}: Found ${files.length} image files`);

    for (const file of files) {
      const info = await getImageInfo(file);
      if (info) {
        assets.push(info);
      }
    }
  }

  console.log(`âœ… Total scanned: ${assets.length} valid images`);
  return assets;
}

// é‡è¤‡æ¤œçŸ¥
export function findDuplicates(assets: AssetInfo[]): DuplicateGroup[] {
  const hashGroups = new Map<string, AssetInfo[]>();

  // ãƒãƒƒã‚·ãƒ¥ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
  for (const asset of assets) {
    if (!hashGroups.has(asset.hash)) {
      hashGroups.set(asset.hash, []);
    }
    hashGroups.get(asset.hash)!.push(asset);
  }

  // é‡è¤‡ã®ã¿æŠ½å‡º
  const duplicates: DuplicateGroup[] = [];

  for (const [hash, files] of hashGroups) {
    if (files.length > 1) {
      // æœ€é©ãªãƒ•ã‚¡ã‚¤ãƒ«é¸æŠï¼ˆå„ªå…ˆé †ä½: çŸ­ã„ãƒ‘ã‚¹ > é«˜è§£åƒåº¦ > å°ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼‰
      const recommended = files.reduce((best, current) => {
        // ãƒ‘ã‚¹ã®æ·±ã•æ¯”è¼ƒ
        const bestDepth = best.path.split(/[/\\]/).length;
        const currentDepth = current.path.split(/[/\\]/).length;

        if (currentDepth < bestDepth) return current;
        if (currentDepth > bestDepth) return best;

        // è§£åƒåº¦æ¯”è¼ƒ
        const bestPixels = best.size.width * best.size.height;
        const currentPixels = current.size.width * current.size.height;

        if (currentPixels > bestPixels) return current;
        if (currentPixels < bestPixels) return best;

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒï¼ˆå°ã•ã„æ–¹ã‚’å„ªå…ˆï¼‰
        return current.fileSize < best.fileSize ? current : best;
      });

      duplicates.push({
        hash,
        count: files.length,
        totalSize: files.reduce((sum, f) => sum + f.fileSize, 0),
        files,
        recommended,
      });
    }
  }

  return duplicates.sort((a, b) => b.totalSize - a.totalSize);
}

// é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
export async function removeDuplicates(
  duplicates: DuplicateGroup[],
  dryRun = true
): Promise<{
  removed: string[];
  savedBytes: number;
  errors: string[];
}> {
  const removed: string[] = [];
  const errors: string[] = [];
  let savedBytes = 0;

  console.log(`ğŸ—‘ï¸  ${dryRun ? "DRY RUN" : "REMOVING"} duplicate files...`);

  for (const group of duplicates) {
    const toRemove = group.files.filter(
      (f) => f.path !== group.recommended.path
    );

    for (const file of toRemove) {
      try {
        console.log(
          `${dryRun ? "ğŸ“‹" : "ğŸ—‘ï¸ "} ${file.path} (${(
            file.fileSize / 1024
          ).toFixed(1)}KB)`
        );

        if (!dryRun) {
          await fs.remove(file.path);
        }

        removed.push(file.path);
        savedBytes += file.fileSize;
      } catch (error) {
        errors.push(`Failed to remove ${file.path}: ${error}`);
      }
    }
  }

  return { removed, savedBytes, errors };
}

// ã‚¹ãƒãƒ¼ãƒˆãƒªãƒãƒ¼ãƒ ï¼ˆä¸€æ„æ€§ä¿è¨¼ï¼‰
export async function smartRename(
  assets: AssetInfo[],
  targetDir = "./src/assets/library"
): Promise<{
  renamedFiles: Array<{ from: string; to: string }>;
  errors: string[];
}> {
  await fs.ensureDir(targetDir);

  const renamedFiles: Array<{ from: string; to: string }> = [];
  const errors: string[] = [];
  const usedNames = new Set<string>();

  console.log("ğŸ·ï¸  Smart renaming assets...");

  for (const asset of assets) {
    try {
      // åŸºæœ¬åç”Ÿæˆ
      let baseName = asset.basename
        .toLowerCase()
        .replace(/[^a-z0-9\-_]/g, "-") // è‹±æ•°å­—ãƒ»ãƒã‚¤ãƒ•ãƒ³ãƒ»ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ä»¥å¤–ã‚’ç½®æ›
        .replace(/-+/g, "-") // é€£ç¶šãƒã‚¤ãƒ•ãƒ³ã‚’çµ±åˆ
        .replace(/^-|-$/g, ""); // å…ˆé ­æœ«å°¾ã®ãƒã‚¤ãƒ•ãƒ³ã‚’å‰Šé™¤

      // ç©ºã®å ´åˆã¯ãƒãƒƒã‚·ãƒ¥ä½¿ç”¨
      if (!baseName) {
        baseName = `img-${asset.hash.slice(0, 8)}`;
      }

      // è§£åƒåº¦æƒ…å ±ä»˜åŠ 
      const resolution = `${asset.size.width}x${asset.size.height}`;
      let newName = `${baseName}_${resolution}${asset.ext}`;

      // é‡è¤‡å›é¿
      let counter = 1;
      while (usedNames.has(newName)) {
        newName = `${baseName}_${resolution}_${counter}${asset.ext}`;
        counter++;
      }

      usedNames.add(newName);
      const newPath = path.join(targetDir, newName);

      await fs.copy(asset.path, newPath);
      renamedFiles.push({ from: asset.path, to: newPath });

      console.log(`ğŸ“ ${path.basename(asset.path)} â†’ ${newName}`);
    } catch (error) {
      errors.push(`Failed to rename ${asset.path}: ${error}`);
    }
  }

  return { renamedFiles, errors };
}

// çµ±è¨ˆæƒ…å ±ç”Ÿæˆ
export function generateStats(
  assets: AssetInfo[],
  duplicates: DuplicateGroup[]
): {
  summary: string;
  details: {
    totalFiles: number;
    totalSize: number;
    duplicateGroups: number;
    duplicateFiles: number;
    wastedSpace: number;
    averageSize: number;
    formatBreakdown: Record<string, number>;
    sizeBreakdown: Record<string, number>;
  };
} {
  const totalFiles = assets.length;
  const totalSize = assets.reduce((sum, a) => sum + a.fileSize, 0);
  const duplicateFiles = duplicates.reduce((sum, d) => sum + (d.count - 1), 0);
  const wastedSpace = duplicates.reduce(
    (sum, d) => sum + d.files.slice(1).reduce((s, f) => s + f.fileSize, 0),
    0
  );

  const formatBreakdown: Record<string, number> = {};
  const sizeBreakdown = { small: 0, medium: 0, large: 0 };

  for (const asset of assets) {
    formatBreakdown[asset.ext] = (formatBreakdown[asset.ext] || 0) + 1;

    if (asset.fileSize < 50000) sizeBreakdown.small++;
    else if (asset.fileSize < 500000) sizeBreakdown.medium++;
    else sizeBreakdown.large++;
  }

  const summary = `
ğŸ“Š Asset Analysis Summary:
â€¢ Total files: ${totalFiles}
â€¢ Total size: ${(totalSize / 1024 / 1024).toFixed(2)} MB
â€¢ Duplicate groups: ${duplicates.length}
â€¢ Duplicate files: ${duplicateFiles}
â€¢ Wasted space: ${(wastedSpace / 1024 / 1024).toFixed(2)} MB (${(
    (wastedSpace / totalSize) *
    100
  ).toFixed(1)}%)
â€¢ Average file size: ${(totalSize / totalFiles / 1024).toFixed(1)} KB

ğŸ¯ Potential savings: ${(wastedSpace / 1024 / 1024).toFixed(
    2
  )} MB by removing ${duplicateFiles} duplicate files
`;

  return {
    summary,
    details: {
      totalFiles,
      totalSize,
      duplicateGroups: duplicates.length,
      duplicateFiles,
      wastedSpace,
      averageSize: totalSize / totalFiles,
      formatBreakdown,
      sizeBreakdown,
    },
  };
}
